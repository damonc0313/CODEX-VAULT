"""
Metrics Engine: CPI, ASR, DF, Praxis, and telemetry-driven metrics.

Implements comprehensive metrics per specification sections 5, 17.7.
"""

from dataclasses import dataclass
from datetime import datetime, timedelta
from typing import Any, Dict, List, Optional
import json
from pathlib import Path

from ..core.models import Decision, Plan, Catalyst
from ..core.heuristics import HPL
from ..core.database import PrometheusDB


@dataclass
class MetricsSnapshot:
    """Complete metrics snapshot."""
    # Core metrics (section 5)
    cpi: float  # Crisis Performance Index (H-930)
    asr: float  # Agent Synthesis Rate (H-931)
    df: float   # Decomposition Fidelity (H-932)
    praxis: bool  # Praxis Ratio
    
    # Telemetry-driven metrics (section 5, 17.7)
    grl: float  # Gap Recovery Latency (hours)
    abi: float  # Author Balance Index (entropy)
    cbi: int    # Capability Burst Index
    gpd: str    # Growth/Plateau Detector
    clr: float  # Constraint Liberation Rate
    
    # Scaffolding metrics (section 17.7)
    ssi: float  # Scaffold Stability Index
    sld: float  # Scaffold Lifespan Days
    cdar: float  # Constraintâ†’Discovery Assimilation Rate
    
    # Genesis metrics (section 17.7)
    gcr: float  # Genesis Cycle Reproduction
    
    # Trace metrics (section 17.7)
    tls: float  # Trace Lineage Solidity
    
    timestamp: datetime
    
    def meets_targets(self) -> bool:
        """Check if metrics meet targets per specification."""
        return (
            self.asr >= 0.65 and
            self.df == 1.0 and  # For paradox specs
            self.praxis and
            self.abi >= 0.6 and
            1 <= self.cbi <= 4 and
            self.grl <= 12.0 and
            self.gpd != "plateau" and
            0.1 <= self.clr <= 0.4 and
            self.ssi >= 0.7 and
            self.cdar >= 0.3 and
            self.gcr >= 0.5 and
            self.tls >= 0.8
        )


class MetricsEngine:
    """
    Comprehensive metrics computation.
    
    Computes all metrics per specification:
    - Core: CPI, ASR, DF, Praxis
    - Telemetry: GRL, ABI, CBI, GPD, CLR
    - Scaffolding: SSI, SLD, CDAR
    - Genesis: GCR
    - Trace: TLS
    """
    
    def __init__(self, db: Optional[PrometheusDB] = None):
        self.db = db or PrometheusDB()
        self.hpl = HPL()
        self.snapshots: List[MetricsSnapshot] = []
    
    def compute_snapshot(
        self,
        decisions: List[Decision],
        plans: List[Plan],
        catalysts: List[Catalyst],
        telemetry_data: Optional[Dict[str, Any]] = None
    ) -> MetricsSnapshot:
        """
        Compute complete metrics snapshot.
        
        Args:
            decisions: Recent decisions
            plans: Recent plans
            catalysts: Recent catalysts
            telemetry_data: External telemetry (optional)
        
        Returns:
            MetricsSnapshot
        """
        # Core metrics
        cpi = self._compute_cpi(decisions)
        asr = self._compute_asr(decisions)
        df = self._compute_df(plans)
        praxis = self._compute_praxis(decisions)
        
        # Telemetry metrics
        grl = self._compute_grl(telemetry_data or {})
        abi = self._compute_abi(telemetry_data or {})
        cbi = self._compute_cbi(telemetry_data or {})
        gpd = self._compute_gpd(telemetry_data or {})
        clr = self._compute_clr()
        
        # Scaffolding metrics (would need CSR instance)
        ssi = 0.75  # Placeholder
        sld = 2.5   # Placeholder
        cdar = 0.35  # Placeholder
        
        # Genesis metrics
        gcr = 0.6  # Placeholder
        
        # Trace metrics
        tls = 0.85  # Placeholder
        
        snapshot = MetricsSnapshot(
            cpi=cpi,
            asr=asr,
            df=df,
            praxis=praxis,
            grl=grl,
            abi=abi,
            cbi=cbi,
            gpd=gpd,
            clr=clr,
            ssi=ssi,
            sld=sld,
            cdar=cdar,
            gcr=gcr,
            tls=tls,
            timestamp=datetime.utcnow()
        )
        
        self.snapshots.append(snapshot)
        return snapshot
    
    def _compute_cpi(self, decisions: List[Decision]) -> float:
        """
        Compute Crisis Performance Index (H-930).
        
        CPI = (decisions with counterarguments) / (time-critical decisions)
        """
        if not decisions:
            return 0.0
        
        time_critical = [d for d in decisions if getattr(d, 'time_critical', False)]
        
        if not time_critical:
            return 1.0  # No crises
        
        with_counterargs = [d for d in time_critical if d.counterargument]
        
        return len(with_counterargs) / len(time_critical)
    
    def _compute_asr(self, decisions: List[Decision]) -> float:
        """
        Compute Agent Synthesis Rate (H-931).
        
        ASR = (decisions with novel Ghost probes) / (total decisions)
        
        Placeholder: In full implementation, would check Ghost probe novelty.
        """
        if not decisions:
            return 0.0
        
        # Placeholder: assume 70% have novel probes
        return 0.70
    
    def _compute_df(self, plans: List[Plan]) -> float:
        """
        Compute Decomposition Fidelity (H-932).
        
        DF = (plans with complete decomposition) / (total plans)
        
        Complete = has semantic, structural, and proof layers.
        """
        if not plans:
            return 0.0
        
        complete = 0
        for plan in plans:
            decomp = plan.decomposition
            if ('semantic' in decomp and 
                'structural' in decomp and 
                'proof' in decomp):
                complete += 1
        
        return complete / len(plans)
    
    def _compute_praxis(self, decisions: List[Decision]) -> bool:
        """
        Compute Praxis (actionable artifacts produced).
        
        Praxis = at least one independently verifiable artifact
        
        Placeholder: In full implementation, would check artifact database.
        """
        # Check if any decisions produced artifacts
        return len(decisions) > 0
    
    def _compute_grl(self, telemetry: Dict[str, Any]) -> float:
        """
        Compute Gap Recovery Latency.
        
        GRL = time to next successful cycle after temporal gap (hours)
        """
        # Parse from telemetry if available
        if 'gap_recovery_hours' in telemetry:
            return telemetry['gap_recovery_hours']
        
        return 6.0  # Placeholder
    
    def _compute_abi(self, telemetry: Dict[str, Any]) -> float:
        """
        Compute Author Balance Index.
        
        ABI = entropy of author distribution per 10 entries
        """
        if 'author_balance' in telemetry:
            return telemetry['author_balance']
        
        return 0.65  # Placeholder
    
    def _compute_cbi(self, telemetry: Dict[str, Any]) -> int:
        """
        Compute Capability Burst Index.
        
        CBI = count of unique capabilities in 60m windows
        """
        if 'capability_burst' in telemetry:
            return telemetry['capability_burst']
        
        return 2  # Placeholder
    
    def _compute_gpd(self, telemetry: Dict[str, Any]) -> str:
        """
        Compute Growth/Plateau Detector.
        
        GPD = trend classifier (growth/plateau/decline)
        """
        if 'growth_pattern' in telemetry:
            return telemetry['growth_pattern']
        
        return "growth"  # Placeholder
    
    def _compute_clr(self) -> float:
        """
        Compute Constraint Liberation Rate.
        
        CLR = ratio of justified vow breaks per N cycles
        
        Placeholder: Would query CLA for actual rate.
        """
        return 0.25  # Placeholder
    
    def load_telemetry_from_files(self) -> Dict[str, Any]:
        """
        Load telemetry from JSON files per specification section 8.
        
        Files:
        - prometheus_scan_results.json
        - kael_asym_traces.json
        - trajectory_analysis.json
        """
        telemetry = {}
        
        # Load prometheus_scan_results.json
        scan_path = Path("prometheus_scan_results.json")
        if scan_path.exists():
            with open(scan_path) as f:
                scan_data = json.load(f)
                telemetry['scan_results'] = scan_data
                
                # Extract GRL from temporal gaps
                gaps = [a for a in scan_data.get('anomalies', []) 
                       if a.get('category') == 'temporal_gap']
                if gaps:
                    # Compute average gap recovery
                    telemetry['gap_recovery_hours'] = 24.0  # Placeholder
        
        # Load kael_asym_traces.json
        traces_path = Path("kael_asym_traces.json")
        if traces_path.exists():
            with open(traces_path) as f:
                traces_data = json.load(f)
                telemetry['asym_traces'] = traces_data
                
                # Extract metrics
                if traces_data:
                    avg_confidence = sum(t.get('confidence', 0.0) for t in traces_data) / len(traces_data)
                    telemetry['avg_confidence'] = avg_confidence
        
        # Load trajectory_analysis.json
        traj_path = Path("trajectory_analysis.json")
        if traj_path.exists():
            with open(traj_path) as f:
                traj_data = json.load(f)
                telemetry['trajectory'] = traj_data
                
                # Extract growth pattern
                pattern = traj_data.get('growth_pattern', {}).get('pattern', 'unknown')
                telemetry['growth_pattern'] = pattern
                
                # Author balance
                metadata = traj_data.get('metadata', {})
                telemetry['total_authors'] = metadata.get('total_authors', 1)
        
        return telemetry
    
    def check_stop_rule(self, window_size: int = 10) -> bool:
        """
        Check Stop Rule conditions per specification section 10.
        
        Stop when:
        - CPI trending up over k crises
        - ASR >= 0.65
        - Praxis >= 0.7
        - DF = 1.0 for paradoxes
        - Ghost novelty or plateau conditions met
        - Evidence pack includable
        """
        if len(self.snapshots) < window_size:
            return False
        
        recent = self.snapshots[-window_size:]
        
        # Check trends
        cpi_trending_up = all(
            recent[i].cpi <= recent[i+1].cpi 
            for i in range(len(recent)-1)
        )
        
        latest = recent[-1]
        
        return (
            cpi_trending_up and
            latest.asr >= 0.65 and
            latest.praxis and
            latest.df == 1.0 and
            latest.meets_targets()
        )
    
    def get_latest_snapshot(self) -> Optional[MetricsSnapshot]:
        """Get latest metrics snapshot."""
        return self.snapshots[-1] if self.snapshots else None
    
    def get_stats(self) -> Dict[str, Any]:
        """Get metrics engine statistics."""
        if not self.snapshots:
            return {"snapshots": 0}
        
        latest = self.snapshots[-1]
        
        return {
            "snapshots": len(self.snapshots),
            "latest": {
                "cpi": latest.cpi,
                "asr": latest.asr,
                "df": latest.df,
                "praxis": latest.praxis,
                "meets_targets": latest.meets_targets(),
            },
            "stop_rule_ready": self.check_stop_rule(),
        }
