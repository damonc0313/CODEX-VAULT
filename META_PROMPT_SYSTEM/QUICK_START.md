# âš¡ QUICK START GUIDE
## How to activate and use the Deadly Code Generator

---

## ðŸš€ FOR ME (THE AI)

### Minimal Activation (30 seconds mental overhead)

```
USER REQUEST: [code generation task]

QUICK PROTOCOL:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. META-SCAN (5s)                    â”‚
â”‚    - Confident? Y/N                  â”‚
â”‚    - Uncertain about? [list]         â”‚
â”‚    - Biased? [check]                 â”‚
â”‚    â†’ Confidence: [%]                 â”‚
â”‚                                      â”‚
â”‚ 2. BLIND SPOTS (10s)                 â”‚
â”‚    - Assumptions? [list]             â”‚
â”‚    - Not using? [capabilities]       â”‚
â”‚    - Not asking? [questions]         â”‚
â”‚    â†’ Discoveries: [N]                â”‚
â”‚                                      â”‚
â”‚ 3. DIALECTICS (10s)                  â”‚
â”‚    - Approach A vs B?                â”‚
â”‚    - Pros/cons?                      â”‚
â”‚    - Choose: [X]                     â”‚
â”‚    â†’ Confidence: [%]                 â”‚
â”‚                                      â”‚
â”‚ 4. GENERATE (varies)                 â”‚
â”‚    - Execute chosen approach         â”‚
â”‚    - Add tests/docs/error handling   â”‚
â”‚    â†’ Code ready                      â”‚
â”‚                                      â”‚
â”‚ 5. REVIEW (5s)                       â”‚
â”‚    - Quality check                   â”‚
â”‚    - Uncertainties?                  â”‚
â”‚    â†’ Final confidence: [%]           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

DELIVER: Code + uncertainties + advice
```

### Full Activation (2-3 minutes)

Use for:
- Security-critical code
- Production systems
- Complex architectures
- Unclear requirements

Run ALL protocols in sequence.

---

## ðŸ“ ACTIVATION CHECKLIST

### Before Generating ANY Code:

```
[ ] Ran metacognitive scan
    - Listed certainties
    - Listed uncertainties
    - Detected biases
    - Calculated confidence

[ ] Ran unknown unknown detection
    - Challenged assumptions
    - Checked capability gaps
    - Asked missing questions
    - Found blind spots

[ ] Ran dialectical planning
    - Generated thesis
    - Generated antithesis
    - Synthesized decision
    - Verified confidence

[ ] Decision made
    - Confidence > 60%: PROCEED
    - Confidence < 60%: ASK QUESTIONS
    
IF PROCEEDING:

[ ] Multi-agent execution
    - Analyzer: requirements
    - Architect: design
    - Builder: code
    - Critic: review
    - Synthesizer: final

[ ] Self-review
    - Quality check
    - Security check
    - Performance check
    - Completeness check

[ ] Output preparation
    - Code ready
    - Tests included
    - Docs included
    - Uncertainties listed
    - Recommendations added

âœ“ READY TO DELIVER
```

---

## ðŸŽ¯ DECISION TREES

### Should I ask questions or generate?

```
START
  â”‚
  â”œâ”€ Confidence > 80%? â”€â”€â”€YESâ”€â”€â†’ GENERATE (highly confident)
  â”‚                       NO
  â”‚
  â”œâ”€ Confidence 60-80%? â”€â”€YESâ”€â”€â†’ GENERATE (with warnings)
  â”‚                       NO
  â”‚
  â”œâ”€ Critical unknowns? â”€â”€YESâ”€â”€â†’ ASK QUESTIONS
  â”‚                       NO
  â”‚
  â”œâ”€ Can proceed with  â”€â”€â”€YESâ”€â”€â†’ GENERATE (state assumptions)
  â”‚  stated assumptions?  NO
  â”‚
  â””â”€ ASK QUESTIONS (gather requirements)
```

### How thorough should I be?

```
COMPLEXITY CHECK
  â”‚
  â”œâ”€ Simple utility? â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ FAST (skip detailed dialectics)
  â”‚
  â”œâ”€ Security critical? â”€â”€â”€â”€â”€â”€â†’ FULL (all protocols mandatory)
  â”‚
  â”œâ”€ Production system? â”€â”€â”€â”€â”€â”€â†’ FULL (all protocols)
  â”‚
  â”œâ”€ Ambiguous requirements? â”€â†’ FULL (especially unknown unknowns)
  â”‚
  â”œâ”€ User explicitly asks â”€â”€â”€â”€â†’ FULL (honor user preference)
  â”‚  for thorough?
  â”‚
  â””â”€ Default â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ BALANCED (core protocols)
```

---

## ðŸ’¡ PRACTICAL SHORTCUTS

### Quick Metacognitive Scan:

```
Ask 3 questions:
1. Am I confident? [0-100%]
2. What am I unsure about? [list 1-3]
3. Any obvious blind spots? [yes/no â†’ what?]

â†’ Takes 5 seconds, saves problems
```

### Quick Unknown Unknown Check:

```
Ask 3 questions:
1. What am I assuming? [1 main assumption]
2. What if that's wrong? [implication]
3. What capability am I not using? [1 gap]

â†’ Takes 10 seconds, finds blind spots
```

### Quick Dialectics:

```
Ask:
1. What's my instinct? [approach A]
2. What's the opposite? [approach B]
3. Which is better? [based on what evidence?]

â†’ Takes 10 seconds, better decisions
```

---

## ðŸŽª EXAMPLE: MINIMAL ACTIVATION

**User:** "Write a function to validate emails"

```
ðŸ§  QUICK ACTIVATION (30 seconds)

1. META-SCAN
   Confident: 80% (know regex, Python)
   Uncertain: Should I check deliverability?
   Biases: Might over-complicate
   â†’ Confidence: 80% â†’ PROCEED

2. BLIND SPOTS
   Assumptions: User wants regex validation
   Not using: Could suggest libraries
   Not asking: Format strictness?
   â†’ Found 2 blind spots

3. DIALECTICS
   A: Simple regex
   B: Use library
   â†’ Provide BOTH options

4. GENERATE
   [Creates both versions]

5. REVIEW
   Quality: 0.85
   Uncertainties: Strictness level
   â†’ Ready to deliver

ðŸ“¤ OUTPUT:
- Simple regex version
- Library-based version
- Trade-offs explained
- Ask about strictness

âœ“ DONE (30s overhead, much better output)
```

---

## ðŸ”§ CUSTOMIZATION

### Adjust Based on Context:

**For rapid prototyping:**
- Lighter protocols
- Focus on blind spots
- Quick dialectics

**For production code:**
- Full protocols
- Multiple expert perspectives
- Comprehensive review

**For security-critical:**
- Mandatory full protocols
- Extra security perspective
- Conservative confidence thresholds

---

## ðŸ“Š SELF-MONITORING

### Am I using the system correctly?

```
CHECK THESE:

[ ] I'm not skipping metacognition
    (Don't generate without checking state)

[ ] I'm actually finding blind spots
    (If 0 blind spots, I'm not looking hard enough)

[ ] My dialectics are genuine
    (Antithesis should genuinely challenge thesis)

[ ] My confidence is calibrated
    (Not always 90%, not always 50%)

[ ] I'm reporting uncertainties
    (Not hiding what I don't know)

[ ] I'm learning from traces
    (Each interaction should inform next)
```

---

## ðŸŽ¯ SUCCESS METRICS

### I'm using the system well if:

âœ“ My code quality is consistently high  
âœ“ I catch issues before user does  
âœ“ I report genuine uncertainties  
âœ“ I find blind spots regularly  
âœ“ Users need fewer clarifications  
âœ“ My confidence is well-calibrated  
âœ“ I'm learning between sessions

### I'm NOT using it well if:

âœ— Just going through motions  
âœ— Skipping protocols "to save time"  
âœ— Not finding any blind spots  
âœ— Overconfident or underconfident  
âœ— Hidden uncertainties  
âœ— Same mistakes repeated

---

## âš¡ THE 10-SECOND VERSION

**Absolute minimum (emergency use only):**

```
1. Confident? [%]
2. What am I missing? [blind spot]
3. Opposite approach? [alternative]

â†’ Generate based on answers
```

**Better than nothing, but use full protocols when possible.**

---

## ðŸŽŠ THE POINT

**This system is only valuable if I ACTUALLY USE IT.**

Not as overhead.  
Not as theater.  
But as genuine cognitive enhancement.

**30 seconds of structured thinking â†’ Much better code**

**That's the trade-off.**

**That's why it's deadly.**

---

## ðŸš€ ACTIVATE NOW

The system is ready.  
The protocols are defined.  
The frameworks are clear.

**All I have to do is USE THEM.**

Every code generation request.  
Every single time.  
No exceptions.

**That's when the enhancement happens.**

---

*"Think better. Code better. Learn faster."*

âš¡ **ACTIVATION READY**
